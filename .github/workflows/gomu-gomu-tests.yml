name: Task - Gomu Gomu no Gatling Performance Tests

on:
  workflow_dispatch:
  workflow_call:

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      BINARY_PATH: ../target/production/madara
    steps:
      - uses: actions/checkout@v3

      - uses: actions/cache@v3
        with:
          path: |
            target/production/madara
          key:
            ${{ runner.os }}-cargo-${{ hashFiles('Cargo.lock') }}-${{
            github.run_id }}
          fail-on-cache-miss: true

      - name: Setup rust toolchain
        run: |
          rustup target add x86_64-unknown-linux-gnu

      - name: Setup build deps (linux)
        run: |
          sudo apt update
          sudo apt install -y clang llvm libudev-dev protobuf-compiler libssl-dev pkg-config

      - name: Setup gomu gomu
        run: |
          set -v -x +e
          cd ..
          git clone https://github.com/keep-starknet-strange/gomu-gomu-no-gatling.git
          cd gomu-gomu-no-gatling
          cargo install --path .

      - name: Setup dev chain
        run: |
          cd ../madara
          ./target/production/madara setup --chain=dev --from-local=configs

      - name: Run gomu gomu test
        run: |-
          set -v -x +e
          ./target/production/madara --dev > madara.log 2>&1 &
          MADARA_RUN_PID=$!
          while ! echo exit | nc localhost 9944; do sleep 1; done
          cd ../gomu-gomu-no-gatling
          RUST_LOG=info cargo run -- shoot -c config/default.yaml
          kill $MADARA_RUN_PID

      - name: Process results
        run: |
          set -v -x +e
          cd ../gomu-gomu-no-gatling
          #### Extract TPS, UOPS, Extrinsics and Steps from the report ####
          jq ' 
          .benches[] |= (.name as $benchName | .metrics[] |= (.name = .name + " ("+ $benchName + ")")) # Append benchmark name to each metric name
          | .benches[].metrics[].extra = .extra # set extra field for each metric
          |.benches # extract only benches
          |map(.metrics)|add # merge metrics from different benches
          |map(select(.name | test("Average TPS|Average UOPS|Average Extrinsics|Average Steps"))) #filter only the metrics we want
          ' report.json > processed_report.json

          #### Extract Failed from the report ####
          jq ' 
          .benches[] |= (.name as $benchName | .metrics[] |= (.name = .name + " ("+ $benchName + ")")) # Append benchmark name to each metric name
          | .benches[].metrics[].extra = .extra # set extra field for each metric
          |.benches # extract only benches
          |map(.metrics)|add # merge metrics from different benches
          |map(select(.name | test("Failed"))) #filter only the metrics we want
          ' report.json > failed_report.json

      - name: Compare result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: "customBiggerIsBetter"
          output-file-path: ./processed_report.json
          alert-threshold: "120%"
          github-token: ${{ secrets.GITHUB_TOKEN }}
          fail-on-alert: true
          summary-always: true
          comment-always: true
          comment-on-alert: false
          auto-push: ${{ github.ref == 'refs/heads/main' }}

      - name: Check for failed requests
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: "customSmallerIsBetter"
          output-file-path: ./failed_report.json
          alert-threshold: "120%"
          github-token: ${{ secrets.GITHUB_TOKEN }}
          fail-on-alert: true
          summary-always: false
          comment-always: false
          comment-on-alert: true
          auto-push: ${{ github.ref == 'refs/heads/main' }}
          benchmark-data-dir-path: "dev/bench-failed"

      - name: Upload madara logs
        uses: actions/upload-artifact@v2
        with:
          name: madara-log
          path: madara.log
        if: always()
